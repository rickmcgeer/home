apiVersion: batch/v1
kind: Job
metadata:
  name: aiko-lora-train
  namespace: jhub
spec:
  template:
    spec:
      containers:
      - name: lora-trainer
        image: gcr.io/YOUR_PROJECT_ID/aiko/loratrainer:latest
        command: ["python", "train_adapter.py"]
        args: ["--model_id", "mistralai/Mistral-7B-Instruct", "--use_qlora"]
        resources:
          limits:
            memory: "24Gi"
            cpu: "2"
            nvidia.com/gpu: "1"
        volumeMounts:
        - name: repo-volume
          mountPath: /workspace
      restartPolicy: Never
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      nodeSelector:
        cloud.google.com/gke-accelerator: "nvidia-l4"
      volumes:
        - name: repo-volume
          persistentVolumeClaim:
            claimName: home-repo-pvc
  backoffLimit: 1